%%%% Proceedings format for most of ACM conferences (with the exceptions listed below) and all ICPS volumes.
\documentclass[sigconf]{acmart}
%%%% As of March 2017, [siggraph] is no longer used. Please use sigconf (above) for SIGGRAPH conferences.

%%%% Proceedings format for SIGPLAN conferences 
% \documentclass[sigplan, anonymous, review]{acmart}

%%%% Proceedings format for SIGCHI conferences
% \documentclass[sigchi, review]{acmart}

%%%% To use the SIGCHI extended abstract template, please visit
% https://www.overleaf.com/read/zzzfqvkmrfzn


\usepackage{booktabs} 	% For formal tables
\usepackage{indentfirst}% For indenting first paragraphs
\usepackage{iftex}
% --------------------------- LATER --------------------------------------


% Copyright 
% I don't know what our copyright is on this?
%\setcopyright{none}
%\setcopyright{acmcopyright}
%\setcopyright{acmlicensed}
\setcopyright{rightsretained}
%\setcopyright{usgov}
%\setcopyright{usgovmixed}
%\setcopyright{cagov}
%\setcopyright{cagovmixed}


% DOI
%\acmDOI{10.475/123_4}

% ISBN
%\acmISBN{123-4567-24-567/08/06}

%Conference
%\acmConference[WOODSTOCK'97]{ACM Woodstock conference}{July 1997}{El
  %Paso, Texas USA}
%\acmYear{1997}
%\copyrightyear{2016}


%\acmArticle{4}
%\acmPrice{15.00}
% ------------------------------------------------------------------------

\begin{document}
\title{Temp Title: Non-Functional Bugs Project}
%\titlenote{Produces the permission block, and copyright information}

\author{Aida Radu}
\affiliation{
  \institution{Dept. of Computing Science \\ University of Alberta}
  \city{Edmonton}
  \state{Canada}
}
\email{aradu@ualberta.ca}

\author{Sarah Nadi}
\affiliation{
  \institution{Dept. of Computing Science \\ University of Alberta}
  \city{Edmonton}
  \country{Canada}
}
\email{nadi@ualberta.ca}


\begin{abstract}
[PLACEHOLDER TEXT]

\end{abstract}

% The code below should be generated by the tool at
% http://dl.acm.org/ccs.cfm

\begin{CCSXML}
	<ccs2012>
	<concept>
	<concept_id>10011007</concept_id>
	<concept_desc>Software and its engineering</concept_desc>
	<concept_significance>500</concept_significance>
	</concept>
    
	<concept>
	<concept_id>10011007.10010940.10011003</concept_id>
	<concept_desc>Software and its engineering~Extra-functional properties</concept_desc>
	<concept_significance>500</concept_significance>
	</concept>
	</ccs2012>
\end{CCSXML}

\ccsdesc[500]{Software and its engineering}
\ccsdesc[500]{Software and its engineering~Extra-functional properties}


\keywords{Repository Mining; Bug Detection}


\maketitle

% ---------------------------------------------------------------------------------------------------
\section{Introduction}
% ---------------------------------------------------------------------------------------------------
\section{Background}
% ---------------------------------------------------------------------------------------------------
\section{Methodology}
To create our dataset, we looked at a variety of Github repositories written in either Java or Python. 
We used three methods to identify candidate repositories for mining. By examining the history of these repositories, we obtained commit messages related to non-functional bugs, which we used to construct our dataset.
 
\subsection{Selecting Projects via Star Rating}
First, we used the Github API to search for projects written in Java or Python, and sorted them based on their number of stars. We then selected the top 90 repositories from these results. 

\subsubsection{Obtaining commits}
To extract commits related to non-functional requirements, we implemented a keyword search using PyDriller \cite{Spadini2018}. The stemmed keywords we use in our search are listed in Table \ref{tab:kwds}. Examples of possible word endings for matches are in square brackets.

% --------------- TABLE -------------
\begin{table}
  \caption{Commit Message Keywords}
  \label{tab:kwds}
\begin{tabular}{ c c c }
  \toprule
   "fix"             &"bug"           &"error"\\
   "refactor"		 &"secur[ity]"    &"maint[enance]"\\
   "stab[ility]"	 &"portab[ility]" &"efficien[cy]"\\
   "usab[ility]" 	 &"reliab[ility]" &"testab[ility]"\\
   "changeab[ility]" &"replac[e]"     &"memory"\\
   "resource"        &"runtime"       &"crash"\\
   "leak"            &"attack"        &"authenticat[ion]"\\
   "authoriz[ation]" &"cipher"        &"crack" \\ 
   "decrypt"         &"encrypt"       &"vulnerab[ility]"\\ 
   "minimiz[e]"      &"optimiz[e]"    &"slow"\\
   "\#"              &"fast"          &"perform[ance]\\
  \bottomrule
\end{tabular}
\end{table}
% --------------- TABLE -------------

Our PyDriller based program mined the commit history of each project, and outputted a CSV file containing the id and commit message containing one or more of the keywords in Table \ref{tab:kwds}. For projects written in Java, we further limited our search to commits affecting \texttt{.java} files. Likewise, for Python projects, we looked only at \texttt{.py} files.

We then manually searched these files for true positives. We ignored commits that, despite containing one or more of the keywords in our list, did not relate to non-functional requirements (e.g., ``Fix copy paste error''\footnote{https://github.com/jenkinsci/jenkins/commit/9fb6ccf} and ``Allow modules to replace visual character representation''\footnote{https://github.com/MovingBlocks/Terasology/commit/45f915a}). Furthermore, we did not focus on problems that were highly specific to the given project. 


\subsection{Selecting Projects via Github Search}
Using our first method, we found several instances where developers corrected memory leaks, or replaced one API with another to improve performance. Noting these patterns, we developed another, more effective strategy for finding  potential target projects. In this second method, we identified candidate repos by using Github's search bar to find relevant patterns. Github searches through a variety of data, including code, commit messages, and issues. We filtered our search to commit messages containing the keywords in Table \ref{tab:kwds}. As well, we searched for commit messages containing language-specific enhancements such as ``StringBuilder replace,'' and ``foreach loop replace,'' since we had seen these in previous projects. We analyzed the bug that was found in the search, then ran our PyDriller program on the complete repo history. Thus, these projects always had at least one potential hit. Once we ran PyDriller, the remaining steps were identical to those in the previous section.

\subsection{Selecting Projects from RepoReapers}
In order to add more examples from well-engineered projects to our dataset, we chose Github repositories from the results of Munaiah et al \cite{Munaiah2017}. This dataset evaluates over a million Github repositories based on characteristics of well-engineered projects. First, we sorted this dataset in descending order of star rating, then chose Java and Python repositories with a True Boolean prediction based on the authors' Random Forest classifier. We chose to focus on this classifier because Munaiah et al reported a higher precision compared to the classifier in their study. Using this dataset, we obtained problems from 8 Java and 5 Python repositories. We then ran our PyDriller program on these repositories as in the previous two methods. 

\subsection{Removing False Positives}

For each identified potential hit, we looked at the code changes that occurred in the commit to ensure the code change was indeed fixing a non-functional property, as described in the commit message. This manual review is necessary since there are sometimes matched commits that do not contain relevant code changes. For example, a commit message may mistakenly claim to improve performance \footnote{https://github.com/adangert/JoustMania/commit/a9711c2}, or it may confuse which APIs or methods were actually changed in the commit \footnote{https://github.com/Offer-Ready/xslt-library/commit/12fbf12}.

\subsection{Documentation} 
Our problems fell into one of three types: General-Practise, API-related, and Project-Specific. General-Practise problems apply to code quality and language-independent practices. API-related problems describe changes where one API or method was improved or swapped with a better API. Project-Specific problems are those that are only applicable to the project in which they occur.
For each problem we identified, we recorded the problem meta data in a YAML\footnote{http://yaml.org/, last checked on June 27, 2018} file. Figure \ref{fig:meta1} shows an example of our format. Each file specifies the problem's \texttt{source}. The source \texttt{commit-msg-keywords} refers to method one, while \texttt{github-search} refers to method two. Under the \texttt{project} field, we specify the \texttt{name} of the project and the \texttt{url} of its Github repository. We also document the \texttt{commit url} and \texttt{commit message} associated with the fix, as well as the particular \texttt{file} and \texttt{method} affected. Because a user's commit message is not always thorough, we construct a \texttt{description} of our interpretation of the problem.

In addition, we assign one or more tags to each problem according to the type of fix. Our collection of tags consists of: \texttt{security}, \texttt{performance}, \texttt{memory}, \texttt{resource management}, and \texttt{determinism}. For fixes related to specific APIs (e.g., using a StringBuilder in place of  a String), we record the involved \texttt{API}. If the developer switched to a different API, we record the \texttt{API change} in the problem documentation. We also assign a \texttt{rule} to the problem, corresponding to the improving change.  For commits not connected to a particular API, we create a general \texttt{suggestion} to address similar problems. An example of this type is shown in Figure \ref{fig:meta2}. 

% --------------- FIGURE -------------
\begin{figure}
  \includegraphics[height=2in, width=3in]{YAMLmetadata}
  \caption{Example YAML file for an API-related problem from \texttt{Fowler}}
  \label{fig:meta1}
\end{figure}
% --------------- FIGURE -------------


% --------------- FIGURE -------------
\begin{figure}
  \includegraphics[height=2in, width=3in]{YAMLmetadata2}
  \caption{Example YAML file for a General practice problem from \texttt{VISNodeWS}}
  \label{fig:meta2}
\end{figure}
% --------------- FIGURE -------------

% ---------------------------------------------------------------------------------------------------
\section{Dataset}

Using the first procedure, we mined 90 Java repositories and 15 Python repositories. Of these, 15 Java and 9 Python repositories contained true positives. In total, we identified 62 problems using this method. Using the second procedure, we obtained 32 problems from 19 Java repositories and 11 Python repositories. With the third procedure, we identified 44 problems from 8 Java and 5 Python repositories. In total, our dataset contains 138 problems from 67 projects. The distribution of problems by type and language is shown in Table \ref{tab:type}.

% --------------- TABLE -------------
\begin{table}

  \caption{Data Distribution by Problem Type}
  \label{tab:type}
\begin{tabular}{ c c c c }
  \toprule
  Problem Type & Python & Java & Total \\
  \midrule
  API Related       &	26  &  71 &  97\\
  General    		&	16  &  19 &  35\\
  Project Specific  &	 2  &   4 &   6\\
  \midrule
  Total      		&	44  &  94 &  138\\
  \bottomrule
\end{tabular}
\end{table}
% --------------- TABLE -------------

The number of problems per tag are displayed in Table \ref{tab:tag}. Performance related bugs were the most common subtype. Table \ref{tab:domain} shows the number of projects in our dataset that have stars,watches, and forks within a given range. Eighteen of the projects had no stars; all of these were identified via the \texttt{github-search} procedure. We decided to keep these projects in the dataset because (1) some of these problems resembled others in more popular repositories and (2) it may interest others to study problems that novice programmers run into. Meanwhile, forty-nine projects had at least one star. Nine of these had between one and forty-nine stars, two had between fifty and 199 stars, seven between 200 and 399 stars, six between 400 and 599 stars, and four had between 600 and 799 stars. Twenty-one projects had 800 or more stars. The majority of projects had less than fifty watches. The majority of  projects had more no more than 400 forks.

We identified 48 different Java APIs and 17 different Python APIs as sources of API-related problems. Fixes for these problems consisted of refining the use of the problematic API, or exchanging it with a more optimal one. The number of problems involving each API is shown in Table \ref{tab:apifreq}. Java's String class contributed to the highest number of API-related problems in that language. These were all \texttt{performance} problems, which developers fixed by using a more efficient API (e.x., StringBuilder) to perform concatenation. In Python, list methods were the biggest source of API-related problems.
% because some have two tags, this has to be a separate table(?), otherwise the totals wouldn't add up
% --------------- TABLE -------------
\begin{table}
  \caption{Data Distribution by Problem Tag}
  \label{tab:tag}
\begin{tabular}{  c c c c }
  \toprule
  Tag  				&Python &Java & Total\\
  \midrule
  security				& 10 &17 &27 \\
  performance			&27 &37 &64 \\
  memory				& 4 &34 &38 \\
  resource management	& 2 & 14&  16 \\
  determinism			& 1 & 2  & 3  \\
  \bottomrule
\end{tabular}
\end{table}
% --------------- TABLE -------------

% --------------- TABLE -------------
\begin{table}
  \caption{Number of Projects by Github Stats}
  \label{tab:domain}
\begin{tabular}{ c c c c }
  \toprule
   & \multicolumn{3}{c}{Projects in Range} \\
   \cline{2-4}
  Range & stars & watches & forks\\
  \midrule
  0			&18 & 5& 21\\
  <50		&9 &39& 11\\
  <200	    & 2 & 14& 16\\
  <400	    & 7 & 4&  4\\
  <600   	& 6 & 1&  5\\
  <800      & 4 & 0&  3\\
  800+      & 21& 4&  8\\
  \bottomrule
\end{tabular}
\end{table}
% --------------- TABLE -------------

% --------------- TABLE -------------
\begin{table*}[t]
  \caption{Frequency of Problematic Java APIs}
  \label{tab:apifreq}
  \addtolength{\tabcolsep}{4pt}
\begin{tabular}{ c c c c}
  \toprule
  \multicolumn{4}{c}{JAVA} \\
  
  API & Occurrence & API & Occurrence\\
  \midrule
  java.lang.String& 8               & java.io.BufferedOutputStream& 1\\
  android.content.Context& 2        & org.apache.commons.io.IOUtils& 1\\
  java.io.FileOutputStream& 2       & hudson.model.Run& 1\\
  java.util.jar& 1                  & hudson.model.Item& 1\\
  java.io.BufferedReader& 2         & hudson.model.Hudson& 3\\
  java.util.zip.ZipFile& 1          & org.kohsuke.stapler.StaplerRequest&1\\
  java.util.ArrayList& 4            & java.io.FileReader& 1\\
  android.util.SparseArray& 1       & squareup.haha.perflib.Snapshot& 1\\
  java.util.Vector& 3               & java.lang.Long& 3\\
  java.lang.StringBuffer& 5         & java.lang.Double& 2\\
  SentienceLab.PointCloudDatasetReader.DataSource& 1 & java.lang.Boolean&1\\
  xtremelabs.robolectric.bytecode.RobolectricClassLoader&1 &java.lang.ref.WeakReference&2    \\
  tinkerpop.pipes.serial.filter.ObjectFilterPipe& 1&java.util.HashMap& 4 \\    
  fasterxml.jackson.annotation.JsonProperty.Access&2&java.lang.annotation.RetentionPolicy& 1\\
  terasology.rendering.nui.NUIManager& 1&java.util.UUID.randomUUID& 1\\
  terasology.physics.engine.PhysicsLiquidWrapper& 1&hudson.remoting.Channel& 1\\
  terasology.entitySystem.entity.EntityRef& 1&android.webkit.WebView&1\\
  java.io.FileInputStream&1&java.awt.image.BufferedImage&1\\
  java.util.HashSet&1&java.io.Closeable&1\\
  javax.imageio.ImageWriter&1&android.webkit.WebSettings&1\\
  com.facebook.common.references.CloseableReference&1&java.lang.Float&2\\
  org.apache.lucene.util.IOUtils&1&org.codehaus.jackson.JsonParser&1\\
  java.util.concurrent.Executors&1&rajawali.util.LittleEndianDataInputStream&1\\
  javax.imageio.ImageReader&1&&\\
  
  
  
 
  \midrule
  
  \multicolumn{4}{c}{PYTHON} \\
  API & Occurrence & API & Occurrence\\
  \midrule
  builtins.io.IOBase& 1              & builtins.list& 5\\
  builtins.input& 1                  & builtins.forloop& 2\\
  builtins.str& 3                    & builtins.map& 3\\
  needle.driver.NeedleWebDriver.assertScreenshot& 1 & django.db.models.Model& 1\\
  simp\_le.IOPlugin& 1               &   builtins.hasattr           &1\\
  Object.\_\_class\_\_.\_\_name\_\_&1&requests&1\\
  sqlite3.Connection&1&numpy&1\\
  copy.deepcopy&1&builtins.generator&1\\
  Lib.json&1&&\\
  
  
  \bottomrule
\end{tabular}
\end{table*}
% --------------- TABLE -------------

% ---------------------------------------------------------------------------------------------------
\section{Discussion and Directions for Future Work}
% ---------------------------------------------------------------------------------------------------
\section{Conclusions}
% ---------------------------------------------------------------------------------------------------
\section*{Threats to Validity}
% ---------------------------------------------------------------------------------------------------
\section*{Acknowledgements}


\bibliographystyle{ACM-Reference-Format}
\bibliography{bibRaduNadi2018}

\end{document}
